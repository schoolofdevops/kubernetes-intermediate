---
phase: 03-core-content
plan: 02
type: execute
wave: 2
depends_on: ["03-01"]
files_modified:
  - docs/section-1/01-overview.mdx
  - docs/section-1/02-reading.md
  - docs/section-1/03-lab.md
  - docs/section-1/quiz.md
autonomous: true

must_haves:
  truths:
    - "Learner can read Module 1 content in 10-20 minutes and understand node affinity, pod affinity/anti-affinity, and taints/tolerations"
    - "Learner can follow the lab to label nodes, apply affinity rules to Voting App components, and verify scheduling behavior"
    - "Learner can answer 12-15 scenario-based quiz questions about pod scheduling"
    - "Module 1 builds on Module 0 state (no fresh cluster creation, uses existing Voting App)"
  artifacts:
    - path: "docs/section-1/02-reading.md"
      provides: "Advanced pod scheduling concepts with diagrams"
      min_lines: 180
    - path: "docs/section-1/03-lab.md"
      provides: "Hands-on scheduling lab with 5 tasks"
      min_lines: 250
    - path: "docs/section-1/quiz.md"
      provides: "12-15 scenario-based scheduling questions"
      min_lines: 120
  key_links:
    - from: "docs/section-1/03-lab.md"
      to: "examples/voting-app/"
      via: "References base Voting App YAMLs from Module 0 as starting state"
      pattern: "Module 0"
    - from: "docs/section-1/02-reading.md"
      to: "docs/section-1/03-lab.md"
      via: "Next Steps info box linking to lab"
      pattern: "lab"
---

<objective>
Create complete Module 1: Advanced Pod Scheduling - teaching learners to control where pods run using node affinity, pod affinity/anti-affinity, taints, and tolerations. The Voting App evolves from random scheduling to intentional placement (postgres on SSD nodes, vote replicas spread across nodes for HA).

Purpose: Scheduling is the first production-readiness improvement. Learners see immediate, visible impact (pods move to specific nodes) which builds motivation. This module carries forward from Module 0.

Output: Complete Module 1 (overview, reading, lab, quiz) with 3-4 Mermaid diagrams and a comprehensive lab covering node labeling, affinity rules, and taints/tolerations.
</objective>

<execution_context>
@/Users/gshah/.claude/get-shit-done/workflows/execute-plan.md
@/Users/gshah/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/phases/03-core-content/03-CONTEXT.md
@.planning/phases/03-core-content/03-RESEARCH.md
@.planning/phases/03-core-content/03-01-SUMMARY.md
@templates/content-template.md
@templates/lab-template.md
@templates/quiz-template.md
@templates/AUTHORING-GUIDE.md
@docs/section-1/01-overview.mdx
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create Module 1 reading materials with overview update and Mermaid diagrams</name>
  <files>
    docs/section-1/01-overview.mdx
    docs/section-1/02-reading.md
  </files>
  <action>
**1. Update docs/section-1/01-overview.mdx:**
Replace the current placeholder content. Create a proper module landing page:
- Title: "Module 1: Advanced Pod Scheduling"
- Frontmatter: sidebar_position: 1, title: "Overview"
- Metadata block: Difficulty: Intermediate, Estimated Time: 90 minutes (15 min reading + 50 min lab + 15 min quiz)
- "What You Will Learn" (5 items): node affinity for workload placement, pod anti-affinity for high availability, taints and tolerations for node dedication, combining scheduling strategies, scheduling impact on the Voting App
- "Prerequisites": Module 0 completed, KIND cluster running with Voting App deployed
- Brief 2-paragraph overview connecting to Production Readiness Journey: "Your Voting App works, but pods land on random nodes. In production, you need databases on fast storage, frontends spread for availability, and dedicated nodes for critical workloads."

**2. Create docs/section-1/02-reading.md:**
Follow templates/content-template.md. Target: 12-18 minute read (~2500-3500 words). Conversational tone, no emojis.

Content structure:
- **Overview** (2-3 paragraphs): The scheduling problem - why random placement is risky. Postgres on a node with low disk I/O? All vote replicas on same node that crashes? Frame as first step in production readiness.
- **How the Scheduler Works** section:
  - Brief explanation (per research: mention scoring, don't deep-dive into algorithms)
  - "The scheduler filters nodes (hard requirements), then scores them (soft preferences). Highest score wins."
  - Include Mermaid sequence diagram: Scheduler workflow (User -> API Server -> Scheduler filters/scores -> Kubelet pulls image, from research Example)
  - Explain "IgnoredDuringExecution" - scheduling decision is one-time, pods don't move after placement
- **Node Affinity** section:
  - requiredDuringSchedulingIgnoredDuringExecution (hard rules - must match)
  - preferredDuringSchedulingIgnoredDuringExecution (soft rules - try to match, with weights 1-100)
  - Include YAML example: postgres deployment with node affinity for disktype=ssd (from research Example 2)
  - Include Mermaid flowchart: Node affinity decision flow (does node have label? -> required: reject/accept, preferred: add weight to score)
  - Practical tip: "Always verify node labels exist BEFORE writing affinity rules. Use `kubectl get nodes --show-labels`"
- **Pod Affinity and Anti-Affinity** section:
  - podAffinity: co-locate pods (e.g., worker near redis for low latency)
  - podAntiAffinity: spread pods (e.g., vote replicas across nodes for HA)
  - topologyKey explained: kubernetes.io/hostname (spread across nodes), topology.kubernetes.io/zone (spread across zones)
  - Include YAML example: vote deployment with pod anti-affinity (from research Example 3)
  - Include Mermaid diagram: 3-node cluster showing vote pods spread across nodes with anti-affinity
- **Taints and Tolerations** section:
  - Analogy: "A taint is a 'No Trespassing' sign. A toleration is the key - but having the key doesn't mean you MUST go there."
  - Three taint effects: NoSchedule, PreferNoSchedule, NoExecute
  - CRITICAL distinction from affinity: taints REPEL, they don't ATTRACT. Must combine taint+toleration+affinity for dedicated node placement.
  - Include brief YAML example of taint + toleration
  - Caution admonition: "A toleration alone does NOT guarantee pod placement on the tainted node. You need affinity rules too."
- **Combining Strategies** section:
  - Real-world pattern: dedicated database node = taint (keep others off) + toleration (postgres allowed) + node affinity (postgres prefers this node)
  - Brief diagram or table showing which strategy solves which problem
- **Summary** with 5 bullet points
- **Further Reading** with links to K8s scheduling docs, assign-pod-node reference
- Info admonition: "Next Steps - Time to apply these scheduling strategies to your Voting App in the lab"

Reference the School of DevOps existing lab (https://kubernetes-tutorial.schoolofdevops.com/advanced_pod_scheduling/) as additional resource in Further Reading.
  </action>
  <verify>
    - Both files exist and are non-empty
    - `npm run build` succeeds
    - 02-reading.md contains at least 3 Mermaid diagram code blocks (scheduler sequence, node affinity flow, pod anti-affinity visualization)
    - 02-reading.md word count is 2500-3500 words
    - 01-overview.mdx has difficulty and time estimate
    - Content explains taint vs affinity distinction clearly (search for "repel" or "attract" concepts)
    - No emojis, all code blocks have language tags
  </verify>
  <done>Module 1 reading materials explain scheduling concepts with 3-4 Mermaid diagrams, clear taint/affinity distinction, practical YAML examples, and conversational tone targeting 12-18 min read time.</done>
</task>

<task type="auto">
  <name>Task 2: Create Module 1 lab and quiz</name>
  <files>
    docs/section-1/03-lab.md
    docs/section-1/quiz.md
  </files>
  <action>
**1. Create docs/section-1/03-lab.md:**
Follow templates/lab-template.md 8-section structure. Duration: 45-55 minutes. Builds on Module 0 state (Voting App already deployed).

Title: "Lab: Scheduling the Voting App for Production"

- **Objectives** (5 items): Label cluster nodes for scheduling experiments, apply node affinity to place postgres on SSD-labeled nodes, use pod anti-affinity to spread vote replicas across nodes, configure taints and tolerations for dedicated workload placement, verify scheduling decisions with kubectl
- **Prerequisites**: Module 0 completed, KIND cluster with 3 worker nodes running, Example Voting App deployed and functional
- **Setup**: Verify existing cluster (`kubectl get nodes`), verify Voting App running (`kubectl get pods`), verify app is functional (quick port-forward check). NO new cluster creation - carry forward from Module 0.
- **Tasks** (5 tasks + 1 challenge):
  - **Task 1: Label Nodes for Scheduling** (from research Example 1):
    Label kind-worker as disktype=ssd, kind-worker2 and kind-worker3 as disktype=hdd.
    Verify with `kubectl get nodes -L disktype`. Show expected output table.
    Explain: "We're simulating SSD vs HDD nodes. In production, these labels represent real hardware differences."
  - **Task 2: Node Affinity for Postgres** (from research Example 2):
    Create postgres-affinity.yaml with requiredDuringSchedulingIgnoredDuringExecution targeting disktype=ssd.
    Apply the updated deployment. Verify postgres pod moves to kind-worker (SSD node) with `kubectl get pod -o wide`.
    Show how to check which node: `kubectl get pod <postgres-pod> -o jsonpath='{.spec.nodeName}'`.
    Explain required vs preferred in context.
  - **Task 3: Pod Anti-Affinity for Vote HA** (from research Example 3):
    Scale vote to 3 replicas. Add preferredDuringSchedulingIgnoredDuringExecution anti-affinity with topologyKey kubernetes.io/hostname.
    Apply updated deployment. Verify pods spread across nodes with `kubectl get pods -o wide -l app=vote`.
    Show expected: 3 vote pods on 3 different nodes.
    Explain: "If one node goes down, 2/3 of vote capacity survives."
  - **Task 4: Taints and Tolerations**:
    Taint kind-worker with dedicated=database:NoSchedule.
    Observe: non-database pods can't schedule new replicas on that node.
    Add toleration to postgres deployment.
    Verify postgres stays on kind-worker (tainted node).
    Show that vote pods avoid the tainted node even with replicas.
    Key learning: Taint REPELS, toleration just ALLOWS. Demonstrate by showing a pod with toleration but no affinity may still end up elsewhere.
  - **Task 5: Combined Strategy - Dedicated Database Node**:
    Combine: taint on kind-worker (keep others off) + toleration on postgres (allowed) + node affinity (prefers kind-worker).
    Apply all three. Verify postgres is on kind-worker, other pods on kind-worker2/3.
    Show the complete picture: dedicated database node with SSD.
  - **Challenge: Scheduling Failure Debugging**:
    Apply a node affinity rule referencing a label that does NOT exist (e.g., disktype=nvme).
    Observe pod stuck in Pending state. Use `kubectl describe pod` to see FailedScheduling events.
    Fix by either adding the label or changing the affinity rule.
    Learning: Always verify labels exist before writing affinity rules.
- **Verification**:
  1. `kubectl get pods -o wide` shows postgres on kind-worker (SSD)
  2. Vote replicas spread across different nodes
  3. No non-database pods on tainted kind-worker node
  4. All Voting App services still functional (port-forward and test vote flow)
- **Cleanup**: Do NOT clean up - Module 2 builds on this. Remove ONLY the taint for cleaner Module 2 start: `kubectl taint nodes kind-worker dedicated=database:NoSchedule-`. Keep labels and affinity rules.
- **Troubleshooting**:
  1. Pod stuck in Pending (label mismatch - from research Pitfall 2)
  2. Pod has toleration but schedules elsewhere (toleration is not affinity - from research Pitfall 3)
  3. Voting App breaks after rescheduling (verify end-to-end flow - from research Pitfall 6)
- **Key Takeaways**: 5 points

All kubectl commands include expected output. YAML files include `title` attributes. Include clear explanations between steps.

**2. Create docs/section-1/quiz.md:**
Follow templates/quiz-template.md. Create 13 questions (8 MCQ, 3 scenario, 2 true/false).

Topics (distribute across all scheduling concepts):
- requiredDuringScheduling vs preferredDuringScheduling difference
- topologyKey purpose and common values
- Taint effects (NoSchedule, PreferNoSchedule, NoExecute)
- Why toleration alone is insufficient for placement (critical misconception)
- Pod anti-affinity for HA (scenario: which config spreads pods?)
- Node affinity operators (In, NotIn, Exists, DoesNotExist)
- Debugging a Pending pod (scenario: what to check first?)
- Scheduler scoring with weights (scenario: which node gets the pod?)
- IgnoredDuringExecution meaning
- Combining strategies for dedicated nodes
- Label best practices
- Voting App scheduling scenario (scenario: where should postgres go and why?)
- Taint vs affinity purpose distinction

Scenario questions should use the Voting App context. Explanations should reference troubleshooting patterns. 60% MCQ, ~25% scenario, ~15% T/F per template guidelines.

Module metadata: Module: 1, Topic: Advanced Pod Scheduling, Question Count: 13
  </action>
  <verify>
    - `docs/section-1/03-lab.md` exists with all 8 sections
    - Lab has 5 main tasks + 1 challenge task
    - Lab references Module 0 as prerequisite (carry-forward)
    - Lab Cleanup section says "Keep resources for Module 2"
    - `docs/section-1/quiz.md` has at least 13 questions
    - Quiz has mix of MCQ, Scenario, True/False
    - `npm run build` succeeds
    - No emojis, all code blocks have language tags
  </verify>
  <done>Module 1 lab walks learners through labeling nodes, applying affinity/anti-affinity, taints/tolerations, and combined strategies with the Voting App. Quiz has 13 questions testing scheduling concepts with scenario-based questions.</done>
</task>

</tasks>

<verification>
- Module 1 has 4 content files: 01-overview.mdx (updated), 02-reading.md, 03-lab.md, quiz.md
- Reading is 12-18 min with 3-4 Mermaid diagrams
- Lab follows 8-section template with 5 tasks + 1 challenge
- Lab builds on Module 0 (no fresh cluster, references existing Voting App)
- Lab cleanup preserves state for Module 2
- Quiz has 13 questions in correct format
- `npm run build` succeeds
- Taint vs affinity distinction is clear in both reading and lab
</verification>

<success_criteria>
Module 1 is complete: scheduling concepts explained with diagrams (12-18 min read), hands-on lab applying affinity/taints to Voting App (45-55 min), and quiz testing understanding (13 questions). Voting App state carries forward to Module 2.
</success_criteria>

<output>
After completion, create `.planning/phases/03-core-content/03-02-SUMMARY.md`
</output>
